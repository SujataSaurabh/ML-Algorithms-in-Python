{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we have discussed the steps of pre-processing for machine learnig. These are: \n",
    "1. load the dataset\n",
    "2. Split the data into input and output variables for machine learning \n",
    "3. apply a pre-processing trasnform to the input variables. \n",
    "4. Data summary analysis to see the change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from numpy import set_printoptions\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, Normalizer, Binarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "file = '../data/pima-indians-diabetes.data.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class'] \n",
    "df = read_csv(file, names= names)\n",
    "array = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate array in to input & output components \n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]  # class "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following are the data preprocessing techniques to bring all the datasets to a common scale. It is essential to avoid unnecessary data overfitting or under-fitting due to inappropriate data scales. \n",
    "1. Min Max Scaler \n",
    "2. Standard Scaler\n",
    "3. Data Normalization\n",
    "4. Binarize data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rescaling data into the range of 0 & 1 --. This is useful for optimization algos used in the core of ML algos like gradient descent. It is also useful for algos that weight inputs like regression & neural nets & algos that use distance measures like k-nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.353 0.744 0.59  0.354 0.    0.501 0.234 0.483]\n",
      " [0.059 0.427 0.541 0.293 0.    0.396 0.117 0.167]\n",
      " [0.471 0.92  0.525 0.    0.    0.347 0.254 0.183]\n",
      " [0.059 0.447 0.541 0.232 0.111 0.419 0.038 0.   ]\n",
      " [0.    0.688 0.328 0.354 0.199 0.642 0.944 0.2  ]]\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "rescaledX_mms = scaler.fit_transform(X)\n",
    "# summarize transformed data\n",
    "set_printoptions(precision=3)\n",
    "print(rescaledX_mms[0:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize data: \n",
    "    It is a technique to transform attributes with a Gaussian distribution & differeing means & standard deviations to a standard Gaussian distribution with a mean of 0 & a standard deviation of 1. This is most suitable for technique that assume a Gaussian distribution in the input variables & work better with rescaled data, such as Linear Regression, Logistic Regression & LDA.  The value for each attribute now have a mean value of 0 & standard deviation of 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.64   0.848  0.15   0.907 -0.693  0.204  0.468  1.426]\n",
      " [-0.845 -1.123 -0.161  0.531 -0.693 -0.684 -0.365 -0.191]\n",
      " [ 1.234  1.944 -0.264 -1.288 -0.693 -1.103  0.604 -0.106]\n",
      " [-0.845 -0.998 -0.161  0.155  0.123 -0.494 -0.921 -1.042]\n",
      " [-1.142  0.504 -1.505  0.907  0.766  1.41   5.485 -0.02 ]]\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler().fit(X)\n",
    "rescaledX_ss = scaler.transform(X)\n",
    "print(rescaledX_ss[0:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalise Data- refers to rescaling each observation to have a length of 1(called unit norm). It is \\\n",
    "      useful for sparse datasets with attributes of varying scales when using algos that weight input values such as neural nets & algos that \\\n",
    "      use distance measures such as k-nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.034 0.828 0.403 0.196 0.    0.188 0.004 0.28 ]\n",
      " [0.008 0.716 0.556 0.244 0.    0.224 0.003 0.261]\n",
      " [0.04  0.924 0.323 0.    0.    0.118 0.003 0.162]\n",
      " [0.007 0.588 0.436 0.152 0.622 0.186 0.001 0.139]\n",
      " [0.    0.596 0.174 0.152 0.731 0.188 0.01  0.144]]\n"
     ]
    }
   ],
   "source": [
    "# NORMALIZE DATA\n",
    "scaler = Normalizer().fit(X)\n",
    "normalizedX = scaler.transform(X)\n",
    "print(normalizedX[0:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binarize data: Transforming the data using a binary threshold. All values above the threshold are marked 1 and all equal to or below are marked as 0. \n",
    "      This is called binarizing your data or thresholding your data. \n",
    "      It can be useful when you have probabilities that you want to make crisp values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 0. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 0. 1. 1. 1.]\n",
      " [1. 1. 1. 0. 0. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# BINARIZE DATA\n",
    "binarizer = Binarizer(threshold=0.0).fit(X)\n",
    "binaryX = binarizer.transform(X)\n",
    "print(binaryX[0:5,:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
